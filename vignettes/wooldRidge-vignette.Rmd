---
title: "wooldRidge-vignette"
author: "Justin M Shea"
date: "`r Sys.Date()`"
output: html_vignette
pdf_document: default
vignette: >
  %\VignetteIndexEntry{wooldRidge-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

An excellent approach to learning is to find an example from your textbook
and then recreate it. Below are examples from every chapter and the syntax 
provided here should get you through most of the book.

Load the `wooldRidge` package to access data in the manner specified in each example.
```{r, echo = TRUE, eval = TRUE, warning=FALSE}
library(wooldRidge)
```

## Chapter 2: The Simple Regression Model

**`Example 2.10:` A Log Wage Equation**

> "Using the wage1 data as in Example 2.4, but using log(wage) as the dependent variable,
we obtain the following relationship:"

$$\widehat{log(wage)} = \beta_0 + \beta_1educ$$

First, load the `wage1` data.
```{r}
data(wage1)
```

Next, estimate a linear relationship between the log of _wage_ and _education_.

```{r}
log_wage_model <- lm(lwage ~ educ, data = wage1)
```

Finally, print the coefficients and $R^2$.

```{r}
log_wage_model$coefficients
summary(log_wage_model)$r.squared
```

## Chapter 3: Multiple Regression Analysis: Estimation

**`Example 3.2:` Hourly Wage Equation**

> "Using the 526 observations on workers in 'wage1', we include $educ$(years of education), $exper$(years of labor market experience), and $tenure$(years with the current employer) in an equation explain log($wage$)."

$$\widehat{log(wage)} = \beta_0 + \beta_1educ + \beta_3exper + \beta_4tenure$$

Estimate the model regressing _education_, _experience_, and _tenure_ against _log(wage)_.
```{r}
hourly_wage_model <- lm(lwage ~ educ + exper + tenure, data = wage1)
```

Again, print the estimated model coefficients:
```{r}
hourly_wage_model$coefficients
```


## Chapter 4: Multiple Regression Analysis: Inference

**`Example 4.7` Effect of Job Training on Firm Scrap Rates**

From the text:

> "The scrap rate for a manufacturing firm is the number of defective items - products that must be discarded - out of every 100 produced. Thus, for a given number of items produced, a decrease in the scrap rate reflects higher worker productivity."

> "We can use the scrap rate to measure the effect of worker training on productivity. Using the data in jtrain, but only for the year 1987 and for nonunionized firms, we obtain the following estimated equation:"

First, load the `jtrain` data set.
```{r, echo = TRUE, eval = TRUE, warning=FALSE}
data("jtrain")
```

Next, create a logical index identifying which observations occur in 1987 and are non-union.

```{r} 
index <- jtrain$year == 1987 & jtrain$union == 0
```

Next, subset the jtrain data by the new index. This returns a data.frame of `jtrain` data of non-union firms for the year 1987.

```{r}
jtrain_1987_nonunion <- jtrain[index,]
```

Now create the linear model regressing hrsemp(total hours training/total employees trained), the log of annual sales, and the log of the number of the employees, against the log of the scrape rate.

$$lscrap = \alpha + \beta_1 hrsemp + \beta_2 lsales + \beta_3 lemploy$$


```{r}
linear_model <- lm(lscrap ~ hrsemp + lsales + lemploy, data = jtrain_1987_nonunion)
```

Finally, print the complete summary statistic diagnostics of the model.
```{r}
summary(linear_model)
```

## Chapter 5: Multiple Regression Analysis: OLS Asymptotics

**`Example 5.3:` Economic Model of Crime**

We illustrate the **Lagrange multiplier (LM) statistics** test by using a slight extension of the crime model from example 3.5.

$$narr86 = \beta_0 + \beta_1pcnv + \beta_2avgsen + \beta_3tottime + \beta_4ptime86 + \beta_5qemp86 + \mu$$

_narr86:_ number of times arrested, 1986.

_pcnv:_ proportion of prior arrests leading to convictions.

_avgsen:_ average sentence served, length in months.

_tottime:_ time in prison since reaching the age of 18, length in months.

_ptime86:_ months in prison during 1986

_qemp86:_ quarters employed, 1986


Load the `crime1` data set containing arrests during the year 1986 and other information on 2,725 men born in either 1960 or 1961 in California.
```{r}
data(crime1)
```

We use the _LM_ statistic to test the null hypothesis that _avgsen_ and _tottime_ have no effect on _narr86_ once other factors have been controlled for. First, estimate the restricted model by regressing _narr86_ on _pcnv, ptime86,_ and _qemp86_; the variables _avgsen_ and _tottime_ are excluded from this regression.

```{r, tidy = TRUE}
restricted_model <- lm(narr86 ~ pcnv + ptime86 + qemp86, data = crime1)
```

We obtain the residuals $\tilde{\mu}$ from this regression, 2,725 of them. 

```{r}
restricted_model_u <- restricted_model$residuals
```

Next, we run the regression of:

$$\tilde{\mu} = \beta_1pcnv + \beta_2avgsen + \beta_3tottime + \beta_4ptime86 + \beta_5qemp86$$
As always, the order in which we list the independent variables is irrelevant.

```{r, tidy = TRUE}
LM_u_model <- lm(restricted_model_u ~ pcnv + ptime86 + qemp86 + avgsen + tottime, data = crime1)
```

This second regression produces $R^2_{\mu}$, which turns out to be about 0.0015.

```{r}
summary(LM_u_model)$r.squared
```


This may seem small, but we must multiple it by _n_ to get the _LM_ statistic: 

$$LM = 2,725(0.0015)$$

```{r}
LM_test <- nobs(LM_u_model) * 0.0015
LM_test
```

The 10% critical value in a chi-square distribution with two degrees of freedom is about 4.61 (rounded to two decimal places). 

```{r}
qchisq(1 - 0.10, 2)
```

Thus, we fail to reject the null hypothesis that $\beta_{avgsen} = 0$ and 
$\beta_{tottime} = 0$ at the 10% level. 

The _p_-value is:
$$P(X^2_{2} > 4.09) \approx 0.129$$
so we would reject the $H_0$ at the 15% level.

```{r}
1-pchisq(LM_test, 2)
```


## Chapter 6: Multiple Regression: Further Issues

**Example 6.1:` Effects of Pollution on Housing Prices, standardized.**

We use the data `hrprice2` to illustrate the use of beta coefficients. 
Recall that the key independent variable is _nox_, a measure of nitrogen oxide
in the air over each community. One way to understand the size of the pollution effect-without getting into the science underling nitrogen oxide's effect on air quality-is to compute beta coefficients. 

The population equation is the level-level model:

$$price = \beta_0 + \beta_1nox + \beta_2crime + \beta_3rooms + \beta_4dist + \beta_5stratio + \mu$$

_price_: median housing price.

_nox_: Nitrous Oxide concentration; parts per million.

_crime_: number of reported crimes per capita.

_rooms_: average number of rooms in houses in the community.

_dist_: weighted distance of the community to 5 employment centers.

_stratio_: average student-teacher ratio of schools in the community.


The beta coefficients are reported in the following equation (so each variable has been converted to its $z$-score):

$$\widehat{zprice} = \beta_1znox + \beta_2zcrime + \beta_3zrooms + \beta_4zdist + \beta_5zstratio$$

First, load the `hrpice2` data.

```r{}
data(hrpice2)

```

Next, estimate the coefficient with the usual `lm` regression model, but this time standardized coefficients by wraping each variable with R's `scale` function:

```{r, tidy = TRUE}
housing_standard <- lm(scale(price)~0+scale(nox)+scale(crime)+scale(rooms)+scale(dist) + scale(stratio), data = hprice2)

housing_standard$coefficients
```

**`Example 6.2:` Effects of Pollution on Housing Prices, Quadratic Interactive Term**

We modify the housing model, adding a quadratic term in _rooms_: 

$$log(price) = \beta_0 + \beta_1log(nox) + \beta_2log(dist) + \beta_3rooms + \beta_4rooms^2 + \beta_5stratio + \mu$$
```{r}
housing_interactive <- lm(lprice ~ lnox + log(dist) + rooms+I(rooms^2) + stratio, data = hprice2)
summary(housing_interactive)
```

## Chapter 7: Multiple Regression Analysis with Qualitative Information 

