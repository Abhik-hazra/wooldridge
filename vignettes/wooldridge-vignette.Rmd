---
title: "wooldridge-vignette"
author: "Justin M Shea"
date: ' '
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
  rmarkdown::html_document:
    toc: yes
vignette: |
  %\VignetteIndexEntry{wooldridge-vignette} %\VignetteEngine{knitr::rmarkdown} %\VignetteEncoding{UTF-8}
---

\newpage

## Introduction

This vignette contains examples of using R with _"Introductory Econometrics: A Modern Approach"_ by Jeffrey M. Wooldridge. Each example illustrates how to load data, run econometric models, and view the results with **R**.

While the course companion site also provides publicly available data sets for Eviews, Excel, MiniTab, and Stata commercial software products, **R** is an open source option. Furthermore, taking the step to use **R** while building a foundation in Econometrics, offers the curious Student a gateway to accessing advanced topics available in the greater package ecosystem.

First, load the `wooldridge` package to access data in the manner specified in each example.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
library(wooldridge)
```

```{r, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}
library(stargazer)
```

## Chapter 2: The Simple Regression Model

**`Example 2.10:` A Log Wage Equation**


$$\widehat{log(wage)} = \beta_0 + \beta_1educ$$

First, load the `wage1` data.
```{r}
data(wage1)
```

Next, estimate a linear relationship between the log of _wage_ and _education_.

```{r}
log_wage_model <- lm(lwage ~ educ, data = wage1)
```

Finally, print the coefficients and $R^2$.

```{r, results = 'asis', warning=FALSE, message=FALSE}
stargazer(log_wage_model, single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 3: Multiple Regression Analysis: Estimation

**`Example 3.2:` Hourly Wage Equation**

$$\widehat{log(wage)} = \beta_0 + \beta_1educ + \beta_3exper + \beta_4tenure$$

Estimate the model regressing _education_, _experience_, and _tenure_ against _log(wage)_.
```{r}
hourly_wage_model <- lm(lwage ~ educ + exper + tenure, data = wage1)
```

Again, print the estimated model coefficients:

```{r, results = 'asis', warning=FALSE, message=FALSE}
stargazer(hourly_wage_model,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 4: Multiple Regression Analysis: Inference

**`Example 4.7` Effect of Job Training on Firm Scrap Rates**


First, load the `jtrain` data set.
```{r, echo = TRUE, eval = TRUE, warning=FALSE}
data("jtrain")
```

Next, create a logical index identifying which observations occur in 1987 and are non-union.

```{r} 
index <- jtrain$year == 1987 & jtrain$union == 0
```

Next, subset the jtrain data by the new index. This returns a data.frame of `jtrain` data of non-union firms for the year 1987.

```{r}
jtrain_1987_nonunion <- jtrain[index,]
```

Now create the linear model regressing hrsemp(total hours training/total employees trained), the log of annual sales, and the log of the number of the employees, against the log of the scrape rate.

$$lscrap = \alpha + \beta_1 hrsemp + \beta_2 lsales + \beta_3 lemploy$$


```{r}
linear_model <- lm(lscrap ~ hrsemp + lsales + lemploy, data = jtrain_1987_nonunion)
```

Finally, print the complete summary statistic diagnostics of the model.

```{r, results = 'asis', warning=FALSE, message=FALSE}
stargazer(linear_model,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 5: Multiple Regression Analysis: OLS Asymptotics

**`Example 5.3:` Economic Model of Crime**


$$narr86 = \beta_0 + \beta_1pcnv + \beta_2avgsen + \beta_3tottime + \beta_4ptime86 + \beta_5qemp86 + \mu$$

$narr86:$ number of times arrested, 1986.

$pcnv:$ proportion of prior arrests leading to convictions.

$avgsen:$ average sentence served, length in months.

$tottime:$ time in prison since reaching the age of 18, length in months.

$ptime86:$ months in prison during 1986

$qemp86:$ quarters employed, 1986


Load the `crime1` data set containing arrests during the year 1986 and other information on 2,725 men born in either 1960 or 1961 in California.

```{r}
data(crime1)
```


```{r, tidy = TRUE}
restricted_model <- lm(narr86 ~ pcnv + ptime86 + qemp86, data = crime1)
```

We obtain the residuals $\tilde{\mu}$ from this regression, 2,725 of them. 

```{r}
restricted_model_u <- restricted_model$residuals
```

Next, we run the regression of:

$$\tilde{\mu} = \beta_1pcnv + \beta_2avgsen + \beta_3tottime + \beta_4ptime86 + \beta_5qemp86$$


```{r, tidy = TRUE}
LM_u_model <- lm(restricted_model_u ~ pcnv + ptime86 + qemp86 + avgsen + tottime, data = crime1)

summary(LM_u_model)$r.square
```

$$LM = 2,725(0.0015)$$

```{r}
LM_test <- nobs(LM_u_model) * 0.0015
LM_test
```


```{r}
qchisq(1 - 0.10, 2)
```


The _p_-value is:
$$P(X^2_{2} > 4.09) \approx 0.129$$
so we would reject the $H_0$ at the 15% level.

```{r}
1-pchisq(LM_test, 2)
```
\newpage

## Chapter 6: Multiple Regression: Further Issues

**`Example 6.1:` Effects of Pollution on Housing Prices, standardized.**


$$price = \beta_0 + \beta_1nox + \beta_2crime + \beta_3rooms + \beta_4dist + \beta_5stratio + \mu$$

$price$: median housing price.

$nox$: Nitrous Oxide concentration; parts per million.

$crime$: number of reported crimes per capita.

$rooms$: average number of rooms in houses in the community.

$dist$: weighted distance of the community to 5 employment centers.

$stratio$: average student-teacher ratio of schools in the community.


$$\widehat{zprice} = \beta_1znox + \beta_2zcrime + \beta_3zrooms + \beta_4zdist + \beta_5zstratio$$
First, load the `hrpice2` data.

```r{}
data(hrpice2)
```

Next, estimate the coefficient with the usual `lm` regression model but this time, standardized coefficients by wrapping each variable with R's `scale` function:

```{r, tidy = TRUE}
housing_standard <- lm(scale(price)~0+scale(nox)+scale(crime)+scale(rooms)+scale(dist) + scale(stratio), data = hprice2)
```

```{r, results = 'asis', warning=FALSE, message=FALSE}
stargazer(housing_standard,  single.row = TRUE, header = FALSE)
```


\newpage

**`Example 6.2:` Effects of Pollution on Housing Prices, Quadratic Interactive Term**

We modify the housing model, adding a quadratic term in _rooms_: 

$$log(price) = \beta_0 + \beta_1log(nox) + \beta_2log(dist) + \beta_3rooms + \beta_4rooms^2 + \beta_5stratio + \mu$$
```{r}
housing_interactive <- lm(lprice ~ lnox + log(dist) + rooms+I(rooms^2) + stratio, data = hprice2)
```

Lets compare the results with the model from `example 6.1`.

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(housing_standard, housing_interactive, single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 7: Multiple Regression Analysis with Qualitative Information 

**`Example 7.4:` Housing Price Regression, Qualitative Binary variable**

This time we use the `hrpice1` data.

```r{}
data(hrpice1)
```

Having just worked with `hrpice2`, it may be helpful to view the documentation on this data set and read the variable names.

```{r, eval=FALSE}
?hprice1
```

$$\widehat{log(price)} = \beta_0 + \beta_1log(lotsize) + \beta_2log(sqrft) + \beta_3bdrms + \beta_4colonial $$

Estimate the coefficients of the above linear model on the `hprice` data set.

```{r, tidy=TRUE}
housing_qualitative <- lm(lprice ~ llotsize + lsqrft + bdrms + colonial, data = hprice1)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(housing_qualitative,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 8: Heteroskedasticity

**`Example 8.9:` Determinants of Personal Computer Ownership**

$$\widehat{PC} = \beta_0 + \beta_1hsGPA + \beta_2ACT + \beta_3parcoll + \beta_4colonial $$

Create a new variable combining the`fathcoll` and `mothcoll`, into `parcoll`. This new column indicates if either parent went to college.

```{r}
data("gpa1")
gpa1$parcoll <- as.integer(gpa1$fathcoll==1 | gpa1$mothcoll)
```

```{r}
GPA_OLS <- lm(PC ~ hsGPA + ACT + parcoll, data = gpa1)
```


First, calculate the weights and then pass them to the same linear model.

```{r}
weights <- GPA_OLS$fitted.values * (1-GPA_OLS$fitted.values)

GPA_WLS <- lm(PC ~ hsGPA + ACT + parcoll, data = gpa1, weights = 1/weights)
```

Compare the OLS and WLS model in the table below:

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(GPA_OLS, GPA_WLS,  single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 9: More on Specification and Data Issues

**`Example 9.8:` R&D Intensity and Firm Size**


$$rdintens = \beta_0 + \beta_1sales + \beta_2profmarg + \mu$$

Load the data, run the model, and apply the `summary` diagnostics function to the model.

```{r}
data(rdchem)
 
all_rdchem <- lm(rdintens ~ sales + profmarg, data = rdchem)
```

Notice the outlier on the far right of the plot.

```{r, tidy=TRUE}
plot_title <- "FIGURE 9.1: Scatterplot of R&D intensity against firm sales"
x_axis <- "firm sales (in millions of dollars)"
y_axis <- "R&D as a percentage of sales"

plot(rdintens ~ sales, pch = 21, bg = "lightblue", data = rdchem, main = plot_title, xlab = x_axis, ylab = y_axis)
```

```{r}
smallest_rdchem <- lm(rdintens ~ sales + profmarg, data = rdchem, 
                      subset = (sales < max(sales)))
```

The table below compares the results of both models side by side. By removing the outlier firm, $sales$ become a more significant determination of R&D expenditures.

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(all_rdchem, smallest_rdchem,  single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 10: Basic Regression Analysis with Time Series Data

**`Example 10.2:` Effects of Inflation and Deficits on Interest Rates**

$$\widehat{i3} = \beta_0 + \beta_1inf_t + \beta_2def_t$$

```{r}
data("intdef")

tbill_model <- lm(i3 ~ inf + def, data = intdef)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(tbill_model, single.row = TRUE, header = FALSE)
```


**`Example 10.11:` Seasonal Effects of Antidumping Filings**

In _Example 10.5_, we used monthly data (in the file `BARIUM`) that have not been seasonally adjusted. 

```{r, tidy=TRUE}
data("barium")
barium_imports <- lm(lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + afdec6, data = barium)
```


```{r, tidy=TRUE}
barium_seasonal <- lm(lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + afdec6 + feb + mar + apr + may + jun + jul + aug + sep + oct + nov + dec, data = barium)

barium_anova <- anova(barium_imports, barium_seasonal)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(barium_imports, barium_seasonal,  single.row = TRUE, header = FALSE)

stargazer(barium_anova,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 11: Further Issues in Using OLS with with Time Series Data

**`Example 11.7:` Wages and Productivity**


$$\widehat{log(hrwage_t)} = \beta_0 + \beta_1log(outphr_t) + \beta_2t + \mu_t$$


```{r}
data("earns")

wage_time <- lm(lhrwage ~ loutphr + t, data = earns)
```

```{r}
wage_diff <- lm(diff(lhrwage) ~ diff(loutphr), data = earns)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(wage_time, wage_diff,  single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 12: Serial Correlation and Heteroskedasticiy in Time Series Regressions

**`Example 12.4`: Prais-Winsten Estimation in the Event Study**

```{r, tidy=TRUE}
data("barium")
barium_model <- lm(lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + afdec6, data = barium)
# Load the `prais` package, use the `prais.winsten` function to estimate.
library(prais)
barium_prais_winsten <- prais.winsten(lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + afdec6, data = barium)
```

```{r}
barium_model
barium_prais_winsten
```


\newpage

**`Example 12.8:` Heteroskedasticity and the Efficient Markets Hypothesis**


$$return_t = \beta_0 + \beta_1return_{t-1} + \mu_t$$



```{r}
data("nyse")
 
return_AR1 <-lm(return ~ return_1, data = nyse)
```



$$\hat{\mu^2_t} = \beta_0 + \beta_1return_{t-1} + residual_t$$



```{r}
return_mu <- residuals(return_AR1)

mu2_hat_model <- lm(return_mu^2 ~ return_1, data = return_AR1$model)
```
```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(return_AR1, mu2_hat_model,  single.row = TRUE, header = FALSE)
```


\newpage

**`Example 12.9:` ARCH in Stock Returns**


$$\hat{\mu^2_t} = \beta_0 + \hat{\mu^2_{t-1}} + residual_t$$

We still have `return_mu` in the working environment so we can use it to create $\hat{\mu^2_t}$, (`mu2_hat`) and $\hat{\mu^2_{t-1}}$ (`mu2_hat_1`). Notice the use `R`'s matrix subset operations to perform the lag operation. We drop the first observation of `mu2_hat` and squared the results. Next, we remove the last observation of `mu2_hat_1` using the subtraction operator combined with a call to the `NROW` function on `return_mu`. Now, both contain $688$ observations and we can run a standard linear model.

```{r}
mu2_hat  <- return_mu[-1]^2

mu2_hat_1 <- return_mu[-NROW(return_mu)]^2

arch_model <- lm(mu2_hat ~ mu2_hat_1)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(arch_model, single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 13: Pooling Cross Sections across Time: Simple Panel Data Methods

**`Example 13.7:` Effect of Drunk Driving Laws on Traffic Fatalities**


$$\widehat{\Delta{dthrte}} = \beta_0 + \Delta{open} + \Delta{admin}$$

```{r}
data("traffic1")

DD_model <- lm(cdthrte ~ copen + cadmn, data = traffic1)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(DD_model,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 14: Advanced Panel Data Methods

**`Example 14.1:` Effect of Job Training on Firm Scrap Rates**

In this section, we will estimate a linear panel modeg using the `plm` function in the
`plm: Linear Models for Panel Data` package.

```{r, tidy=TRUE}
library(plm)

data("jtrain")

scrap_panel <- plm(lscrap ~ d88 + d89 + grant + grant_1, data = jtrain,
            index = c('fcode','year'), model = 'within', effect ='individual')
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(scrap_panel,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 15: Instrumental Variables Estimation and Two Stage Least Squares

**`Example 15.1:` Estimating the Return to Education for Married Women**


$$log(wage) = \beta_0 + \beta_1educ + \mu$$

```{r, message=FALSE}
data("mroz")
wage_educ_model <- lm(lwage ~ educ, data = mroz)
```


$$\widehat{educ} = \beta_0 + \beta_1fatheduc$$

We run the typical linear model, but notice the use of the `subset` argument. `inlf` is a binary variable in which a value of 1 means they are "In the Labor Force". By sub-setting the `mroz` data.frame by observations in which `inlf==1`, only working women will be in the sample.

```{r}
fatheduc_model <- lm(educ ~ fatheduc, data = mroz, subset = (inlf==1))
```

In this section, we will perform an **Instrumental-Variable Regression**, using the  `ivreg` function in the `AER (Applied Econometrics with R)` package.

```{r, message=FALSE}
library("AER")
wage_educ_IV <- ivreg(lwage ~ educ | fatheduc, data = mroz)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(wage_educ_model, fatheduc_model, wage_educ_IV, single.row = TRUE, header = FALSE)
```


\newpage

**`Example 15.2:` Estimating the Return to Education for Men**


$$\widehat{educ} = \beta_0 + sibs$$

```{r, warning=FALSE}
data("wage2")
 
educ_sibs_model <- lm(educ ~ sibs, data = wage2)
```


$$\widehat{log(wage)} = \beta_0 + educ$$

In this section, we will perform an **Instrumental-Variable Regression**, using the  `ivreg` function in the `AER (Applied Econometrics with R)` package.

```{r, message=FALSE}
library("AER")

educ_sibs_IV <- ivreg(lwage ~ educ | sibs, data = wage2)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(educ_sibs_model, educ_sibs_IV, wage_educ_IV,  single.row = TRUE, header = FALSE)
```

\newpage

**`Example 15.5:` Return to Education for Working Women**


$$\widehat{log(wage)} = \beta_0 + \beta_1educ + \beta_2exper + \beta_3exper^2$$

```{r, tidy=TRUE}
data("mroz")
wage_educ_exper_IV <- ivreg(lwage ~ educ + exper + expersq | exper + expersq + motheduc + fatheduc, data = mroz)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE, echo=FALSE}
stargazer(wage_educ_exper_IV,  single.row = TRUE, header = FALSE)
```

\newpage

## Chapter 16: Simultaneous Equations Models

**`Example 16.4:` INFLATION AND OPENNESS**


$$inf = \beta_{10} + \alpha_1open + \beta_{11}log(pcinc) + \mu_1$$
$$open = \beta_{20} + \alpha_2inf + \beta_{21}log(pcinc) + \beta_{22}log(land) + \mu_2$$

**`Example 16.6:` INFLATION AND OPENNESS**


$$\widehat{open} = \beta_0 + \beta_{1}log(pcinc) + \beta_{2}log(land)$$


```{r}
data("openness")
 
open_model <-lm(open ~ lpcinc + lland, data = openness)
```

$$\widehat{inf} = \beta_0 + \beta_{1}open + \beta_{2}log(pcinc)$$

```{r}
library(AER)

inflation_IV <- ivreg(inf ~ open + lpcinc | lpcinc + lland, data = openness)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(open_model, inflation_IV,  single.row = TRUE, header = FALSE)
```


\newpage


## Chapter 17: Limited Dependent Variable Models and Sample Selection Corrections

**`Example 17.3:` POISSON REGRESSION FOR NUMBER OF ARRESTS**

```{r, tidy=TRUE, warning=FALSE}
data("crime1")

formula <- (narr86 ~ pcnv + avgsen + tottime + ptime86 + qemp86 + inc86 + black + hispan + born60)

econ_crime_model <- lm(formula, data = crime1)

econ_crim_poisson <- glm(formula, data = crime1, family=poisson)
```

```{r, results = 'asis', warning=FALSE, message=FALSE, tidy=TRUE}
stargazer(econ_crime_model, econ_crim_poisson,  single.row = TRUE, header = FALSE)
```


\newpage

## Chapter 18: Advanced Time Series Topics

**`Example 18.8:` FORECASTING THE U.S. UNEMPLOYMENT RATE**


$$\widehat{unemp_t} = \beta_0 + \beta_1unem_{t-1}$$

$$\widehat{unemp_t} = \beta_0 + \beta_1unem_{t-1} + \beta_2inf_{t-1}$$

```{r}
data("phillips")

unem_AR1 <- lm(unem ~ unem_1, data = phillips, subset = (year <= 1996))

unem_inf_VAR1 <- lm(unem ~ unem_1 + inf_1, data = phillips, subset = (year <= 1996))
```

```{r, results = 'asis', warning=FALSE, message=FALSE, echo=FALSE}
stargazer(unem_AR1, unem_inf_VAR1,  single.row = TRUE, header = FALSE)
```

# References
